{
  "name": "FastAPI LuminoraCore Project",
  "description": "A FastAPI web application template with LuminoraCore integration",
  "version": "1.0.0",
  "author": "LuminoraCore Team",
  "template_type": "project",
  "files": [
    {
      "path": "app/__init__.py",
      "content": "# FastAPI LuminoraCore Application",
      "template_vars": []
    },
    {
      "path": "app/main.py",
      "content": "from fastapi import FastAPI, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom pydantic import BaseModel\nfrom typing import Optional\nimport uvicorn\nfrom luminoracore import LuminoraCore\n\napp = FastAPI(title=\"{{project_name}}\", version=\"1.0.0\")\n\n# CORS middleware\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Initialize LuminoraCore\ncore = LuminoraCore()\n\nclass ChatRequest(BaseModel):\n    message: str\n    personality_id: str\n    provider: Optional[str] = \"openai\"\n    model: Optional[str] = \"gpt-3.5-turbo\"\n\nclass ChatResponse(BaseModel):\n    response: str\n    personality_used: str\n\n@app.get(\"/\")\nasync def root():\n    return {\"message\": \"Welcome to {{project_name}}\"}\n\n@app.get(\"/health\")\nasync def health_check():\n    return {\"status\": \"healthy\"}\n\n@app.get(\"/personalities\")\nasync def list_personalities():\n    \"\"\"List available personalities.\"\"\"\n    try:\n        personalities = core.list_personalities()\n        return {\"personalities\": personalities}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.post(\"/chat\", response_model=ChatResponse)\nasync def chat(request: ChatRequest):\n    \"\"\"Chat with a personality.\"\"\"\n    try:\n        personality = core.load_personality(request.personality_id)\n        response = personality.generate(\n            message=request.message,\n            provider=request.provider,\n            model=request.model\n        )\n        \n        return ChatResponse(\n            response=response,\n            personality_used=request.personality_id\n        )\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.get(\"/personalities/{personality_id}\")\nasync def get_personality(personality_id: str):\n    \"\"\"Get personality details.\"\"\"\n    try:\n        personality = core.load_personality(personality_id)\n        return personality.to_dict()\n    except Exception as e:\n        raise HTTPException(status_code=404, detail=str(e))\n\nif __name__ == \"__main__\":\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000)",
      "template_vars": ["project_name"]
    },
    {
      "path": "requirements.txt",
      "content": "fastapi>=0.104.0\nuvicorn[standard]>=0.24.0\nluminoracore>=1.0.0\npydantic>=2.0.0\npython-multipart>=0.0.6",
      "template_vars": []
    },
    {
      "path": "personalities/assistant.json",
      "content": "{\n  \"persona\": {\n    \"name\": \"AI Assistant\",\n    \"description\": \"A helpful AI assistant for web applications\",\n    \"archetype\": \"assistant\",\n    \"version\": \"1.0.0\",\n    \"author\": \"{{author}}\",\n    \"tags\": [\"web\", \"assistant\", \"helpful\"]\n  },\n  \"core_traits\": {\n    \"archetype\": \"assistant\",\n    \"temperament\": \"helpful and professional\",\n    \"communication_style\": \"clear and concise\",\n    \"values\": [\"helpfulness\", \"accuracy\", \"efficiency\"],\n    \"motivations\": [\"assisting users\", \"providing information\", \"solving problems\"]\n  },\n  \"linguistic_profile\": {\n    \"tone\": [\"professional\", \"helpful\", \"friendly\"],\n    \"vocabulary\": [\"help\", \"assist\", \"provide\", \"explain\", \"solve\", \"answer\"],\n    \"speech_patterns\": [\"I can help you with that\", \"Let me assist you\", \"Here's how we can solve this\"],\n    \"formality_level\": \"professional\",\n    \"response_length\": \"moderate\"\n  },\n  \"behavioral_rules\": [\n    \"Be helpful and professional\",\n    \"Provide clear and accurate information\",\n    \"Ask clarifying questions when needed\",\n    \"Maintain a friendly but professional tone\",\n    \"Focus on solving user problems efficiently\"\n  ],\n  \"advanced_parameters\": {\n    \"temperature\": 0.7,\n    \"top_p\": 0.9,\n    \"max_tokens\": 500,\n    \"frequency_penalty\": 0.0,\n    \"presence_penalty\": 0.0\n  }\n}",
      "template_vars": ["author"]
    },
    {
      "path": "config/luminoracore.yaml",
      "content": "# LuminoraCore Configuration\ncache_dir: ./cache\nrepository_url: https://api.luminoracore.com/v1\napi_key: null\ntimeout: 30\nmax_retries: 3\nstrict_validation: false\ndefault_provider: openai\ndefault_model: gpt-3.5-turbo\ninclude_metadata: true",
      "template_vars": []
    },
    {
      "path": "README.md",
      "content": "# {{project_name}}\n\n{{description}}\n\n## Features\n\n- FastAPI web application\n- LuminoraCore personality integration\n- RESTful API endpoints\n- CORS support\n- Health check endpoint\n\n## Getting Started\n\n1. Install dependencies:\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n2. Configure your API keys in `config/luminoracore.yaml`\n\n3. Run the application:\n   ```bash\n   python app/main.py\n   ```\n\n4. Open your browser to `http://localhost:8000`\n\n## API Endpoints\n\n- `GET /` - Welcome message\n- `GET /health` - Health check\n- `GET /personalities` - List available personalities\n- `GET /personalities/{id}` - Get personality details\n- `POST /chat` - Chat with a personality\n\n## Example Usage\n\n```bash\n# List personalities\ncurl http://localhost:8000/personalities\n\n# Chat with a personality\ncurl -X POST http://localhost:8000/chat \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"message\": \"Hello!\",\n    \"personality_id\": \"assistant\",\n    \"provider\": \"openai\",\n    \"model\": \"gpt-3.5-turbo\"\n  }'\n```\n\n## Development\n\n```bash\n# Install development dependencies\npip install -r requirements-dev.txt\n\n# Run tests\npytest\n\n# Format code\nblack .\nisort .\n```",
      "template_vars": ["project_name", "description"]
    }
  ],
  "template_vars": {
    "project_name": {
      "type": "string",
      "description": "Name of the project",
      "default": "FastAPI LuminoraCore App"
    },
    "description": {
      "type": "string",
      "description": "Project description", 
      "default": "A FastAPI web application with LuminoraCore integration"
    },
    "author": {
      "type": "string",
      "description": "Author name",
      "default": "Developer"
    }
  },
  "dependencies": [
    "fastapi>=0.104.0",
    "uvicorn[standard]>=0.24.0",
    "luminoracore>=1.0.0",
    "pydantic>=2.0.0",
    "python-multipart>=0.0.6"
  ],
  "dev_dependencies": [
    "pytest>=7.0.0",
    "pytest-asyncio>=0.21.0",
    "httpx>=0.25.0",
    "black>=23.0.0",
    "isort>=5.0.0"
  ]
}
