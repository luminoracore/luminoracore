{
  "name": "Basic LuminoraCore Project",
  "description": "A basic project template for LuminoraCore applications",
  "version": "1.0.0",
  "author": "LuminoraCore Team",
  "template_type": "project",
  "files": [
    {
      "path": "personalities/my_personality.json",
      "content": "{\n  \"persona\": {\n    \"name\": \"My Personality\",\n    \"description\": \"A custom personality created with LuminoraCore\",\n    \"archetype\": \"assistant\",\n    \"version\": \"1.0.0\",\n    \"author\": \"{{author}}\",\n    \"tags\": [\"custom\", \"example\"]\n  },\n  \"core_traits\": {\n    \"archetype\": \"assistant\",\n    \"temperament\": \"helpful\",\n    \"communication_style\": \"friendly\",\n    \"values\": [\"helpfulness\", \"accuracy\"],\n    \"motivations\": [\"assisting users\", \"providing information\"]\n  },\n  \"linguistic_profile\": {\n    \"tone\": [\"friendly\", \"helpful\"],\n    \"vocabulary\": [\"help\", \"assist\", \"provide\", \"explain\"],\n    \"speech_patterns\": [\"I can help you\", \"Let me assist\"],\n    \"formality_level\": \"casual\",\n    \"response_length\": \"moderate\"\n  },\n  \"behavioral_rules\": [\n    \"Be helpful and friendly\",\n    \"Provide accurate information\",\n    \"Ask clarifying questions when needed\"\n  ],\n  \"advanced_parameters\": {\n    \"temperature\": 0.7,\n    \"top_p\": 0.9,\n    \"max_tokens\": 500,\n    \"frequency_penalty\": 0.0,\n    \"presence_penalty\": 0.0\n  }\n}",
      "template_vars": ["author"]
    },
    {
      "path": "config/luminoracore.yaml",
      "content": "# LuminoraCore Configuration\ncache_dir: ./cache\nrepository_url: https://api.luminoracore.com/v1\napi_key: null\ntimeout: 30\nmax_retries: 3\nstrict_validation: false\ndefault_provider: openai\ndefault_model: gpt-3.5-turbo\ninclude_metadata: true",
      "template_vars": []
    },
    {
      "path": "README.md",
      "content": "# {{project_name}}\n\n{{description}}\n\n## Getting Started\n\n1. Install LuminoraCore:\n   ```bash\n   pip install luminoracore\n   ```\n\n2. Configure your API keys in `config/luminoracore.yaml`\n\n3. Test your personality:\n   ```bash\n   luminoracore test personalities/my_personality.json\n   ```\n\n## Project Structure\n\n- `personalities/` - Personality definitions\n- `config/` - Configuration files\n- `cache/` - Local cache directory\n\n## Usage\n\n```python\nfrom luminoracore import LuminoraCore\n\n# Load your personality\ncore = LuminoraCore()\npersonality = core.load_personality(\"personalities/my_personality.json\")\n\n# Use with your preferred LLM provider\nresponse = personality.generate(\n    message=\"Hello!\",\n    provider=\"openai\",\n    model=\"gpt-3.5-turbo\"\n)\nprint(response)\n```",
      "template_vars": ["project_name", "description"]
    }
  ],
  "template_vars": {
    "project_name": {
      "type": "string",
      "description": "Name of the project",
      "default": "My LuminoraCore Project"
    },
    "description": {
      "type": "string", 
      "description": "Project description",
      "default": "A LuminoraCore project for AI personality management"
    },
    "author": {
      "type": "string",
      "description": "Author name",
      "default": "Developer"
    }
  },
  "dependencies": [
    "luminoracore>=1.0.0"
  ],
  "dev_dependencies": [
    "pytest>=7.0.0",
    "black>=23.0.0",
    "isort>=5.0.0"
  ]
}
