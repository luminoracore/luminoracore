# Data Flow and Persistence - LuminoraCore v1.1

**Complete clarification about what's saved where, what's updated, and how the system works**

---

## âš ï¸ CRITICAL CLARIFICATIONS

### 1. Personality JSON is NEVER updated

```
âŒ INCORRECT:
- Load alicia.json
- User increases affinity
- Modify alicia.json with new affinity  â† NO!

âœ… CORRECT:
- Load alicia.json (ONCE, immutable)
- User increases affinity
- Save affinity in DB (PostgreSQL/SQLite/etc)
- Apply modifiers from JSON in memory (temporary)
```

**The JSON file is a TEMPLATE, not a state.**

---

### 2. States are saved in DB, NOT in JSON

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Personality JSON (IMMUTABLE)                            â”‚
â”‚ - alicia.json                                           â”‚
â”‚ - Defines base behavior                                 â”‚
â”‚ - Defines possible levels                               â”‚
â”‚ - Defines possible moods                                â”‚
â”‚ - NEVER changes                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ State DB (MUTABLE)                                      â”‚
â”‚ - PostgreSQL / SQLite / MongoDB                         â”‚
â”‚ - Stores: affinity, current_mood, session_state         â”‚
â”‚ - Constantly updated                                    â”‚
â”‚ - Persists between sessions                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Vector DB (SEARCH)                                      â”‚
â”‚ - pgvector / Pinecone                                   â”‚
â”‚ - Stores: message embeddings                            â”‚
â”‚ - Only for semantic search                              â”‚
â”‚ - Does NOT replace current DB                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 3. Dynamic Compilation is FAST (not slow)

**Compile = Apply deltas, not regenerate everything**

```python
# Compilation takes ~1-5ms (very fast)
base = {"empathy": 0.95, "formality": 0.3}
modifier = {"empathy": +0.2, "formality": -0.1}
compiled = apply_deltas(base, modifier)  # {"empathy": 1.0, "formality": 0.2}
# Time: ~1ms
```

vs

```python
# LLM call takes ~500-2000ms (slow)
response = await llm.generate(prompt)
# Time: ~500-2000ms
```

**Compilation is 500x faster than LLM.**

---

## ğŸ“Š Separation of Responsibilities

### What goes in EACH storage

| Data Type | Storage | Mutable | Persistence |
|-----------|---------|---------|-------------|
| **Base personality** | `alicia.json` (file) | âŒ NO | Permanent |
| **Defined levels/moods** | `alicia.json` (file) | âŒ NO | Permanent |
| **Current conversation** | Redis / Memory | âœ… YES | Current session |
| **Message history** | PostgreSQL / SQLite | âœ… YES | Permanent |
| **User facts** | PostgreSQL / SQLite | âœ… YES | Permanent |
| **Episodes** | PostgreSQL / SQLite | âœ… YES | Permanent |
| **Current affinity** | PostgreSQL / SQLite | âœ… YES | Permanent |
| **Current mood** | PostgreSQL / SQLite / Redis | âœ… YES | Session or permanent |
| **Embeddings** | pgvector / Pinecone | âœ… YES | Permanent |

---

## ğŸ”„ Complete Flow: Sending a Message

### Flow Diagram with Times

```
User sends: "Hello Alicia, you're very pretty"
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. LOAD CONTEXT (async, parallel)                   â”‚  â±ï¸ ~50ms
â”‚    â”œâ”€ Load personality JSON (if not cached)         â”‚
â”‚    â”œâ”€ Get affinity from DB                          â”‚
â”‚    â”œâ”€ Get current mood from DB                      â”‚
â”‚    â””â”€ Get last 10 messages from DB                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. COMPILE PERSONALITY (in memory)                  â”‚  â±ï¸ ~5ms
â”‚    â”œâ”€ Base (from JSON)                              â”‚
â”‚    â”œâ”€ + Level by affinity (from JSON)               â”‚
â”‚    â”œâ”€ + Current mood (from JSON)                    â”‚
â”‚    â””â”€ = Compiled personality (in memory)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. GENERATE RESPONSE (LLM)                          â”‚  â±ï¸ ~1500ms â† BOTTLENECK
â”‚    - Call to DeepSeek/OpenAI/etc                    â”‚
â”‚    - With compiled personality + context            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. POST-RESPONSE PROCESSING (async, parallel)       â”‚  â±ï¸ ~200ms (background)
â”‚    â”œâ”€ Extract facts (light LLM call)                â”‚
â”‚    â”œâ”€ Detect new mood (light LLM call)              â”‚
â”‚    â”œâ”€ Update affinity (calculation)                 â”‚
â”‚    â”œâ”€ Detect episode (every 5 messages)             â”‚
â”‚    â”œâ”€ Create embeddings (API call)                  â”‚
â”‚    â””â”€ Save everything to DB                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
       Return response to user

TOTAL: ~1555ms (user sees response before step 4)
       Step 4 runs in background
```

---

## ğŸ¯ Answers to Your Questions

### Q1: "Recompile with each message?"

**Yes, but it's VERY fast (~5ms).**

```python
# Pseudocode of the process
async def send_message(session_id, message):
    # 1. Load context (parallel) - ~50ms
    affinity = await db.get_affinity(session_id)        # ~10ms
    mood = await db.get_mood(session_id)                # ~10ms
    personality_json = load_cached("alicia.json")       # ~1ms (cache)
    recent_messages = await db.get_messages(session_id, limit=10)  # ~30ms
    
    # 2. Compile personality (in memory) - ~5ms
    compiled = compile_dynamic(
        base=personality_json,
        affinity=affinity,      # Ex: 45
        mood=mood               # Ex: "shy"
    )
    # This only applies deltas:
    # empathy: 0.95 + 0.2 (friend) + 0.0 (shy) = 1.0
    # formality: 0.3 + (-0.1) (friend) + 0.2 (shy) = 0.4
    
    # 3. Generate response (LLM) - ~1500ms â† THIS is the slow one
    response = await llm.generate(
        personality=compiled,
        context=recent_messages,
        message=message
    )
    
    # 4. Return immediately
    return response
    
    # 5. Background processing (doesn't block) - ~200ms
    asyncio.create_task(process_post_response(session_id, message, response))
```

**User sees response in ~1555ms, where 1500ms is the LLM (inevitable).**

---

### Q2: "Does JSON get updated?"

**NO. JSON is NEVER updated.**

```python
# âŒ NEVER do this:
personality_json["advanced_parameters"]["empathy"] = new_value
save_json(personality_json)  # NO!

# âœ… Do this:
# JSON is a READ-ONLY template
# States are saved in DB
await db.update_affinity(session_id, new_affinity)  # Save in PostgreSQL
await db.update_mood(session_id, new_mood)          # Save in PostgreSQL
```

**Analogy:**
```
JSON is like a COOKING RECIPE.
- The recipe does NOT change when you cook
- But each time you cook, you adjust ingredients based on context
- The adjustments are temporary, the recipe remains
```

---

### Q3: "Does it only persist while chatting?"

**NO. It persists PERMANENTLY in DB.**

```sql
-- Affinity table (PostgreSQL/SQLite)
CREATE TABLE user_affinity (
    user_id VARCHAR(255),
    personality_name VARCHAR(255),
    affinity_points INTEGER,        -- Persists here
    current_level VARCHAR(50),      -- Persists here
    last_updated TIMESTAMP
);

-- Session mood table
CREATE TABLE session_moods (
    session_id VARCHAR(255),
    current_mood VARCHAR(50),       -- Persists here
    mood_intensity FLOAT,           -- Persists here
    mood_started_at TIMESTAMP
);
```

**Persistence flow:**

```python
# Day 1, Message 1
await send_message(session_id, "Hello")
# Affinity: 0 â†’ 1
# Saved in DB: affinity=1

# Day 1, Message 2
await send_message(session_id, "You're pretty")
# Affinity: 1 â†’ 3
# Saved in DB: affinity=3, mood="shy"

# User closes the app
# ...

# Day 2, new chat
session_id = await create_session(...)  # Can be new session
# System loads:
# - affinity = 3 (from DB)
# - mood = "neutral" (reset per new session, OPTIONAL)
# - Base personality (from JSON)

# Compiles with affinity=3
# User continues where they left off
```

---

## ğŸ’¾ Multi-Layer Persistence System

### Layer 1: JSON Files (Personalities - IMMUTABLE)

```
luminoracore/personalities/
â”œâ”€â”€ alicia.json              â† Immutable template
â”œâ”€â”€ mika.json                â† Immutable template
â””â”€â”€ yumi.json                â† Immutable template

Use:
- Loaded ONCE at startup (or from cache)
- NEVER modified
- Define base behavior + possible modifiers
```

### Layer 2: Relational DB (States - MUTABLE)

```
PostgreSQL / SQLite (YOUR CHOICE)

Tables:
â”œâ”€â”€ sessions                 â† Conversation sessions
â”œâ”€â”€ messages                 â† Message history
â”œâ”€â”€ user_affinity            â† Affinity points per user/personality
â”œâ”€â”€ session_moods            â† Current mood per session
â”œâ”€â”€ user_facts               â† Learned facts about user
â””â”€â”€ episodes                 â† Memorable episodes

Use:
- Constantly updated
- Persists between sessions
- Your CURRENT system (SQLite, JSON file, etc.) keeps working
- We only add new tables
```

### Layer 3: Vector DB (Semantic Search - OPTIONAL)

```
pgvector (PostgreSQL extension) / Pinecone

Tables:
â””â”€â”€ message_embeddings       â† Vectors for semantic search

Use:
- OPTIONAL (only if you enable semantic search)
- Does NOT replace your current DB
- Is ADDITIONAL for "remember when..." queries
- If you don't use it, everything keeps working (without semantic search)
```

---

## ğŸ”‘ Final Answer to All Your Doubts

### 1. Does JSON get updated?
**NO. JSON is immutable. States in DB.**

### 2. Recompile each message?
**YES, but it's fast (~5ms). LLM is the slow part.**

### 3. Only persists during chat?
**NO. Persists PERMANENTLY in DB.**

### 4. How does it classify what goes to JSON?
**Nothing goes to JSON. States go to DB.**

### 5. Slower process?
**NO. Background tasks don't block (async).**

### 6. Parallel process with AI?
**YES. Fact extraction, mood detection, etc. are async.**

### 7. What happens to current JSON/SQLite?
**They keep working. We only add tables.**

### 8. Does vector DB replace current ones?
**NO. It's ADDITIONAL (only for semantic search).**

### 9. How does it retrieve memories?
**Multi-source: recent messages + facts + episodes + vector search.**

### 10. LLM memory?
**LuminoraCore ENRICHES the LLM context window with info from the past.**

---

## ğŸ“Š Persistence Summary Table

| Data | Where Defined | Where Persists | Mutable | Lifetime |
|------|---------------|----------------|---------|----------|
| **Base personality** | `alicia.json` | JSON file | âŒ NO | Permanent |
| **Possible levels** | `alicia.json` | JSON file | âŒ NO | Permanent |
| **Possible moods** | `alicia.json` | JSON file | âŒ NO | Permanent |
| **Current affinity** | - | DB (SQLite/PostgreSQL) | âœ… YES | Permanent |
| **Current mood** | - | DB + Cache (Redis) | âœ… YES | Session or permanent |
| **Messages** | - | DB (SQLite/PostgreSQL) | âœ… YES | Permanent |
| **Facts** | - | DB (SQLite/PostgreSQL) | âœ… YES | Permanent |
| **Episodes** | - | DB (SQLite/PostgreSQL) | âœ… YES | Permanent |
| **Embeddings** | - | Vector DB (pgvector/Pinecone) | âœ… YES | Permanent |
| **Compiled personality** | - | RAM (temporary, per request) | - | 1 request |

---

<div align="center">

**Made with â¤ï¸ by Ereace - Ruly Altamirano**

</div>

