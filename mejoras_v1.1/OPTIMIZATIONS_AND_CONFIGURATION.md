# Optimizations and Configuration - LuminoraCore v1.1

**How to optimize costs, performance, and configure the ENTIRE system**

---

## âš¡ YOUR QUESTIONS ANSWERED

### 1. âœ… Batch Processing of Embeddings

**YES, it's BETTER and MUST be configurable.**

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURATION (EVERYTHING in JSON or config)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

embedding_config = {
    "provider": "openai",  # openai, cohere, deepseek, local
    "model": "text-embedding-3-small",
    "batch_size": 10,  # â† CONFIGURABLE
    "batch_timeout": 30,  # seconds
    "enabled": True
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SAVINGS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Without batch (1 call per message):
# 100 messages Ã— $0.0001 Ã— 1 call = $0.01
# Time: 100 Ã— 100ms = 10,000ms (10 seconds)

# With batch of 10:
# 100 messages Ã· 10 batch Ã— $0.0001 = $0.001
# Time: 10 batch Ã— 150ms = 1,500ms (1.5 seconds)

# SAVINGS: 90% costs, 85% time âœ…
```

---

### 2. âœ… Embedding Provider Configurability

**YES, it should be selectable based on what's compiled.**

```json
// In alicia.json (Template)
{
  "persona": {...},
  
  "memory_config": {
    "semantic_search": {
      "enabled": true,
      "embedding_provider": "openai",  // â† CONFIGURABLE
      "embedding_model": "text-embedding-3-small",
      "batch_processing": {
        "enabled": true,
        "batch_size": 10,  // â† CONFIGURABLE
        "batch_timeout_seconds": 30
      }
    }
  }
}
```

---

### 3. âœ… Where Embeddings and Sentiment are Saved

**In DB, NOT in JSON Template.**

```sql
-- Embeddings table
CREATE TABLE message_embeddings (
    id UUID PRIMARY KEY,
    message_id VARCHAR(255),
    embedding vector(1536),  -- pgvector
    created_at TIMESTAMP
);

-- Sentiment analysis table
CREATE TABLE sentiment_analysis (
    id UUID PRIMARY KEY,
    message_id VARCHAR(255),
    sentiment VARCHAR(50),  -- positive, negative, neutral
    intensity FLOAT,  -- 0-1
    emotions JSONB,  -- ["joy", "affection", ...]
    created_at TIMESTAMP
);
```

**Data is saved in DB, NOT in the JSON Template (which is immutable).**

---

### 4. âœ… Export (Snapshots) - VERY IMPORTANT

**YES, when you export, it includes ALL evolution from DB.**

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EXPORT SNAPSHOT (Template + DB State â†’ JSON)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

snapshot = await client.export_snapshot(
    session_id="session_123",
    include_options={
        "conversation_history": True,  # Messages
        "facts": True,                 # Learned facts (from DB)
        "episodes": True,              # Episodes (from DB)
        "affinity_progression": True,  # Affinity history (from DB)
        "mood_history": True,          # Mood history (from DB)
        "embeddings": False,           # âš ï¸ VERY heavy, better not
        "sentiment_data": True         # Sentiment analysis (from DB)
    }
)
```

**This Snapshot JSON is PORTABLE:**
- âœ… You can import it into another app
- âœ… You can share it
- âœ… You can migrate it to another LLM
- âœ… Contains ALL evolution

---

## ğŸ’° Cost Comparison

### Option A: All Cloud APIs (âŒ Expensive)

```python
# Per message:
# - Main LLM (DeepSeek cloud): $0.014 / message
# - Mood detection (DeepSeek cloud): $0.002 / message
# - Fact extraction (DeepSeek cloud): $0.003 / message
# - Sentiment (DeepSeek cloud): $0.001 / message
# - Embeddings (OpenAI): $0.0001 / message

# TOTAL: $0.0201 / message

# 1000 messages/day:
# $0.0201 Ã— 1000 = $20.10 / day
# $20.10 Ã— 30 = $603 / month âŒ EXPENSIVE
```

---

### Option B: Cloud Main + Local Processing (âœ… Better)

```python
# Per message:
# - Main LLM (DeepSeek cloud): $0.014 / message
# - Mood detection (YOUR SERVER): $0 / message âœ…
# - Fact extraction (YOUR SERVER): $0 / message âœ…
# - Sentiment (YOUR SERVER): $0 / message âœ…
# - Embeddings (OpenAI batch): $0.00001 / message âœ…

# TOTAL: $0.01401 / message

# 1000 messages/day:
# $0.01401 Ã— 1000 = $14.01 / day
# $14.01 Ã— 30 = $420 / month

# SAVINGS: $603 - $420 = $183/month (30% savings) âœ…
```

---

## ğŸ¯ FINAL RECOMMENDATION

### Optimal Setup for You

```json
{
  "processing_config": {
    // Main LLM: DeepSeek Cloud (conversations)
    "main_llm": {
      "provider": "deepseek",
      "endpoint": "https://api.deepseek.com/v1",
      "model": "deepseek-chat"
    },
    
    // Processing LLM: YOUR LOCAL SERVER âœ…
    "processing_llm": {
      "provider": "deepseek-local",
      "endpoint": "http://localhost:8000/v1",
      "model": "deepseek-r1-distill-llama-8b"
    },
    
    // Embeddings: Batch with OpenAI âœ…
    "embedding_provider": {
      "provider": "openai",
      "model": "text-embedding-3-small",
      "batch_processing": {
        "enabled": true,
        "batch_size": 10,
        "batch_timeout": 30
      }
    }
  }
}
```

**Costs:**
- Main LLM (cloud): $14/day
- Processing LLM (local): $0/day âœ…
- Embeddings (batch): $0.10/day âœ…
- **Total: ~$420/month** (vs $603 without optimization)

**Performance:**
- User: 1555ms (identical to v1.0)
- Background: 150ms average
- Total: No visible impact âœ…

---

<div align="center">

**Everything is configurable. Everything is optimizable. Speed is NOT a problem.**

**Made with â¤ï¸ by Ereace - Ruly Altamirano**

</div>

