# Flujo de Datos y Persistencia - LuminoraCore v1.1

**AclaraciÃ³n completa sobre quÃ© se guarda dÃ³nde, quÃ© se actualiza, y cÃ³mo funciona el sistema**

---

## âš ï¸ ACLARACIONES CRÃTICAS

### 1. El JSON de Personalidad NUNCA se actualiza

```
âŒ INCORRECTO:
- Cargar alicia.json
- Usuario aumenta afinidad
- Modificar alicia.json con nueva afinidad  â† NO!

âœ… CORRECTO:
- Cargar alicia.json (UNA VEZ, inmutable)
- Usuario aumenta afinidad
- Guardar afinidad en BBDD (PostgreSQL/SQLite/etc)
- Aplicar modificadores del JSON en memoria (temporal)
```

**El archivo JSON es un TEMPLATE, no un estado.**

---

### 2. Estados se guardan en BBDD, NO en JSON

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ JSON de Personalidad (INMUTABLE)                        â”‚
â”‚ - alicia.json                                           â”‚
â”‚ - Define comportamiento base                            â”‚
â”‚ - Define niveles posibles                               â”‚
â”‚ - Define moods posibles                                 â”‚
â”‚ - NUNCA cambia                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BBDD de Estados (MUTABLE)                               â”‚
â”‚ - PostgreSQL / SQLite / MongoDB                         â”‚
â”‚ - Guarda: affinity, current_mood, session_state         â”‚
â”‚ - Se actualiza constantemente                           â”‚
â”‚ - Persiste entre sesiones                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BBDD Vectorial (BÃšSQUEDA)                               â”‚
â”‚ - pgvector / Pinecone                                   â”‚
â”‚ - Guarda: embeddings de mensajes                        â”‚
â”‚ - Solo para semantic search                             â”‚
â”‚ - NO reemplaza BBDD actual                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 3. CompilaciÃ³n DinÃ¡mica es RÃPIDA (no lenta)

**Compilar = Aplicar deltas, no regenerar todo**

```python
# CompilaciÃ³n toma ~1-5ms (muy rÃ¡pido)
base = {"empathy": 0.95, "formality": 0.3}
modifier = {"empathy": +0.2, "formality": -0.1}
compiled = apply_deltas(base, modifier)  # {"empathy": 1.0, "formality": 0.2}
# Tiempo: ~1ms
```

vs

```python
# Llamada al LLM toma ~500-2000ms (lento)
response = await llm.generate(prompt)
# Tiempo: ~500-2000ms
```

**La compilaciÃ³n es 500x mÃ¡s rÃ¡pida que el LLM.**

---

## ğŸ“Š SeparaciÃ³n de Responsabilidades

### QuÃ© va en CADA storage

| Tipo de Dato | Storage | Mutable | Persistencia |
|--------------|---------|---------|--------------|
| **Personalidad base** | `alicia.json` (archivo) | âŒ NO | Permanente |
| **Niveles/moods definidos** | `alicia.json` (archivo) | âŒ NO | Permanente |
| **ConversaciÃ³n actual** | Redis / Memory | âœ… SÃ | SesiÃ³n actual |
| **Historial de mensajes** | PostgreSQL / SQLite | âœ… SÃ | Permanente |
| **Facts del usuario** | PostgreSQL / SQLite | âœ… SÃ | Permanente |
| **Episodios** | PostgreSQL / SQLite | âœ… SÃ | Permanente |
| **Afinidad actual** | PostgreSQL / SQLite | âœ… SÃ | Permanente |
| **Mood actual** | PostgreSQL / SQLite / Redis | âœ… SÃ | SesiÃ³n o permanente |
| **Embeddings** | pgvector / Pinecone | âœ… SÃ | Permanente |

---

## ğŸ”„ Flujo Completo: EnvÃ­o de Mensaje

### Diagrama de Flujo con Tiempos

```
Usuario envÃ­a: "Hola Alicia, eres muy linda"
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. CARGAR CONTEXTO (async, paralelo)                â”‚  â±ï¸ ~50ms
â”‚    â”œâ”€ Cargar personalidad JSON (si no en cachÃ©)     â”‚
â”‚    â”œâ”€ Obtener affinity de BBDD                      â”‚
â”‚    â”œâ”€ Obtener mood actual de BBDD                   â”‚
â”‚    â””â”€ Obtener Ãºltimos 10 mensajes de BBDD           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. COMPILAR PERSONALIDAD (en memoria)               â”‚  â±ï¸ ~5ms
â”‚    â”œâ”€ Base (del JSON)                               â”‚
â”‚    â”œâ”€ + Nivel segÃºn affinity (del JSON)             â”‚
â”‚    â”œâ”€ + Mood actual (del JSON)                      â”‚
â”‚    â””â”€ = Personalidad compilada (en memoria)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. GENERAR RESPUESTA (LLM)                          â”‚  â±ï¸ ~1500ms â† BOTTLENECK
â”‚    - Llamada a DeepSeek/OpenAI/etc                  â”‚
â”‚    - Con personalidad compilada + contexto          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. PROCESAMIENTO POST-RESPUESTA (async, paralelo)   â”‚  â±ï¸ ~200ms (background)
â”‚    â”œâ”€ Extraer facts (LLM call ligero)               â”‚
â”‚    â”œâ”€ Detectar mood nuevo (LLM call ligero)         â”‚
â”‚    â”œâ”€ Actualizar affinity (cÃ¡lculo)                 â”‚
â”‚    â”œâ”€ Detectar episodio (cada 5 mensajes)           â”‚
â”‚    â”œâ”€ Crear embeddings (API call)                   â”‚
â”‚    â””â”€ Guardar todo en BBDD                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
       Retornar respuesta al usuario

TOTAL: ~1555ms (usuario ve respuesta antes del step 4)
       Step 4 corre en background
```

---

## ğŸ¯ Respuestas a tus Preguntas

### Q1: "Â¿Con cada mensaje se recompila?"

**SÃ­, pero es MUY rÃ¡pido (~5ms).**

```python
# PseudocÃ³digo del proceso
async def send_message(session_id, message):
    # 1. Cargar contexto (paralelo) - ~50ms
    affinity = await db.get_affinity(session_id)        # ~10ms
    mood = await db.get_mood(session_id)                # ~10ms
    personality_json = load_cached("alicia.json")       # ~1ms (cachÃ©)
    recent_messages = await db.get_messages(session_id, limit=10)  # ~30ms
    
    # 2. Compilar personalidad (en memoria) - ~5ms
    compiled = compile_dynamic(
        base=personality_json,
        affinity=affinity,      # Ej: 45
        mood=mood               # Ej: "shy"
    )
    # Esto solo aplica deltas:
    # empathy: 0.95 + 0.2 (friend) + 0.0 (shy) = 1.0
    # formality: 0.3 + (-0.1) (friend) + 0.2 (shy) = 0.4
    
    # 3. Generar respuesta (LLM) - ~1500ms â† ESTE es el lento
    response = await llm.generate(
        personality=compiled,
        context=recent_messages,
        message=message
    )
    
    # 4. Retornar inmediatamente
    return response
    
    # 5. Procesamiento background (no bloquea) - ~200ms
    asyncio.create_task(process_post_response(session_id, message, response))
```

**Usuario ve la respuesta en ~1555ms, donde 1500ms es el LLM (inevitable).**

---

### Q2: "Â¿Se actualiza el JSON?"

**NO. El JSON NUNCA se actualiza.**

```python
# âŒ NUNCA hacemos esto:
personality_json["advanced_parameters"]["empathy"] = new_value
save_json(personality_json)  # NO!

# âœ… Hacemos esto:
# El JSON es un template de LECTURA
# Los estados se guardan en BBDD
await db.update_affinity(session_id, new_affinity)  # Guarda en PostgreSQL
await db.update_mood(session_id, new_mood)          # Guarda en PostgreSQL
```

**AnalogÃ­a:**
```
El JSON es como una RECETA de cocina.
- La receta NO cambia cuando cocinas
- Pero cada vez que cocinas, ajustas ingredientes segÃºn contexto
- Los ajustes son temporales, la receta permanece
```

---

### Q3: "Â¿Solo persiste mientras se habla?"

**NO. Persiste PERMANENTEMENTE en BBDD.**

```sql
-- Tabla de afinidad (PostgreSQL/SQLite)
CREATE TABLE user_affinity (
    user_id VARCHAR(255),
    personality_name VARCHAR(255),
    affinity_points INTEGER,        -- Persiste aquÃ­
    current_level VARCHAR(50),      -- Persiste aquÃ­
    last_updated TIMESTAMP
);

-- Tabla de mood de sesiÃ³n
CREATE TABLE session_moods (
    session_id VARCHAR(255),
    current_mood VARCHAR(50),       -- Persiste aquÃ­
    mood_intensity FLOAT,           -- Persiste aquÃ­
    mood_started_at TIMESTAMP
);
```

**Flujo de persistencia:**

```python
# DÃ­a 1, Mensaje 1
await send_message(session_id, "Hola")
# Affinity: 0 â†’ 1
# Se guarda en BBDD: affinity=1

# DÃ­a 1, Mensaje 2
await send_message(session_id, "Eres linda")
# Affinity: 1 â†’ 3
# Se guarda en BBDD: affinity=3, mood="shy"

# Usuario cierra la app
# ...

# DÃ­a 2, nuevo chat
session_id = await create_session(...)  # Puede ser nueva sesiÃ³n
# Sistema carga:
# - affinity = 3 (desde BBDD)
# - mood = "neutral" (reseteado por nueva sesiÃ³n, OPCIONAL)
# - Personalidad base (desde JSON)

# Compila con affinity=3
# Usuario sigue donde lo dejÃ³
```

---

### Q4: "Â¿CÃ³mo clasifica quÃ© va al JSON segÃºn el formato?"

**Nada va AL JSON. El JSON es inmutable.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ARCHIVO JSON (Inmutable)                            â”‚
â”‚ - Define estructura de personalidad                 â”‚
â”‚ - Define niveles posibles                           â”‚
â”‚ - Define moods posibles                             â”‚
â”‚ - NO se actualiza nunca                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Lee una vez (cacheado)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MEMORIA RAM (Temporal, por request)                 â”‚
â”‚ - Personalidad base (del JSON)                      â”‚
â”‚ - Estados actuales (de BBDD):                       â”‚
â”‚   * affinity = 45                                   â”‚
â”‚   * mood = "shy"                                    â”‚
â”‚ - CompilaciÃ³n dinÃ¡mica (aplicar modificadores)      â”‚
â”‚ - Personalidad compilada final (solo en RAM)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Persiste en
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BASE DE DATOS (Permanente)                          â”‚
â”‚ - user_affinity (affinity_points, current_level)    â”‚
â”‚ - session_moods (current_mood, intensity)           â”‚
â”‚ - messages (historial de conversaciÃ³n)              â”‚
â”‚ - user_facts (facts extraÃ­dos)                      â”‚
â”‚ - episodes (episodios memorables)                   â”‚
â”‚ - message_embeddings (vectores para bÃºsqueda)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**El JSON solo se lee, nunca se escribe.**

---

### Q5: "Â¿El proceso no serÃ­a mÃ¡s lento en el chat?"

**NO, porque el procesamiento pesado va en BACKGROUND.**

```python
async def send_message(session_id, message):
    # ============================================
    # FOREGROUND (bloquea, debe ser rÃ¡pido)
    # ============================================
    
    # 1. Cargar contexto - ~50ms
    affinity = await db.get_affinity(session_id)
    mood = await db.get_mood(session_id)
    personality = load_cached("alicia.json")  # CachÃ©
    
    # 2. Compilar - ~5ms
    compiled = compile_dynamic(personality, affinity, mood)
    
    # 3. Generar respuesta LLM - ~1500ms (inevitable)
    response = await llm.generate(compiled + message)
    
    # 4. Guardar mensaje en BBDD - ~20ms
    await db.save_message(session_id, message, response)
    
    # TOTAL FOREGROUND: ~1575ms
    # Usuario ve respuesta AQUÃ âœ…
    
    # ============================================
    # BACKGROUND (NO bloquea, puede ser lento)
    # ============================================
    
    # Lanzar tareas en background
    asyncio.create_task(
        process_memory_async(session_id, message, response)
    )
    
    # Retornar inmediatamente
    return response


async def process_memory_async(session_id, message, response):
    """
    Procesamiento de memoria en background
    NO bloquea la respuesta al usuario
    """
    # Estas tareas corren en paralelo
    await asyncio.gather(
        extract_facts(message),              # ~300ms (LLM ligero)
        detect_mood(message, context),       # ~200ms (LLM ligero)
        update_affinity(session_id),         # ~10ms (cÃ¡lculo)
        create_embedding(message),           # ~100ms (API OpenAI)
        detect_episode_if_needed(session_id) # ~400ms (LLM, cada 5 msgs)
    )
    
    # TOTAL BACKGROUND: ~400ms (paralelo)
    # Pero el usuario YA tiene su respuesta
```

**Timeline del usuario:**

```
T=0ms:     Usuario envÃ­a mensaje
T=50ms:    Sistema carga contexto
T=55ms:    Sistema compila personalidad
T=1555ms:  Usuario recibe respuesta âœ… (ve la respuesta aquÃ­)
T=1955ms:  Background: facts extraÃ­dos, affinity actualizada, embeddings creados
```

**El usuario NO espera el procesamiento de memoria.**

---

### Q6: "Â¿No deberÃ­amos tener un proceso paralelo que haga esto con IA?"

**Â¡Exacto! Ya estÃ¡ diseÃ±ado asÃ­.**

```python
# ARQUITECTURA PROPUESTA

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Main Thread (Usuario esperando)         â”‚
â”‚                                         â”‚
â”‚  1. Cargar contexto        [50ms]      â”‚
â”‚  2. Compilar personalidad  [5ms]       â”‚
â”‚  3. Llamar LLM             [1500ms]    â”‚
â”‚  4. Retornar respuesta     âœ…          â”‚
â”‚                                         â”‚
â”‚  TOTAL: 1555ms                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Background Worker (Async)               â”‚
â”‚                                         â”‚
â”‚  5. Extract facts (LLM)    [300ms]     â”‚
â”‚  6. Detect mood (LLM)      [200ms]     â”‚
â”‚  7. Update affinity        [10ms]      â”‚
â”‚  8. Create embeddings      [100ms]     â”‚
â”‚  9. Detect episode         [400ms]     â”‚
â”‚  10. Save all to DB        [50ms]      â”‚
â”‚                                         â”‚
â”‚  TOTAL: 400ms (paralelo)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Usuario ve respuesta en 1.5s âœ…
Sistema procesa memoria en background
```

---

## ğŸ’¾ Sistema de Persistencia Multi-Capa

### Capa 1: Archivos JSON (Personalidades - INMUTABLES)

```
luminoracore/personalities/
â”œâ”€â”€ alicia.json              â† Template inmutable
â”œâ”€â”€ mika.json                â† Template inmutable
â””â”€â”€ yumi.json                â† Template inmutable

Uso:
- Se cargan UNA VEZ al inicio (o desde cachÃ©)
- NUNCA se modifican
- Definen comportamiento base + posibles modificadores
```

### Capa 2: BBDD Relacional (Estados - MUTABLE)

```
PostgreSQL / SQLite (TU ELECCIÃ“N)

Tablas:
â”œâ”€â”€ sessions                 â† Sesiones de conversaciÃ³n
â”œâ”€â”€ messages                 â† Historial de mensajes
â”œâ”€â”€ user_affinity            â† Puntos de afinidad por usuario/personalidad
â”œâ”€â”€ session_moods            â† Mood actual por sesiÃ³n
â”œâ”€â”€ user_facts               â† Facts aprendidos del usuario
â””â”€â”€ episodes                 â† Episodios memorables

Uso:
- Se actualiza constantemente
- Persiste entre sesiones
- Tu sistema ACTUAL (SQLite, JSON file, etc.) sigue funcionando
- Solo agregamos tablas nuevas
```

### Capa 3: BBDD Vectorial (BÃºsqueda SemÃ¡ntica - OPCIONAL)

```
pgvector (extensiÃ³n PostgreSQL) / Pinecone

Tablas:
â””â”€â”€ message_embeddings       â† Vectores para bÃºsqueda semÃ¡ntica

Uso:
- OPCIONAL (solo si habilitas semantic search)
- NO reemplaza tu BBDD actual
- ES ADICIONAL para "recuerdas cuando..." queries
- Si no la usas, todo sigue funcionando (sin semantic search)
```

---

## ğŸ”„ QuÃ© Pasa con tus BBDD Actuales

### Sistema Actual v1.0

```
TU SISTEMA ACTUAL:
â”œâ”€â”€ JSON files (para conversaciones)
â”‚   â””â”€â”€ session_123.json
â”‚       â”œâ”€â”€ messages: [...]
â”‚       â””â”€â”€ context: {...}
â”‚
â”œâ”€â”€ SQLite (para persistencia)
â”‚   â””â”€â”€ conversations.db
â”‚       â””â”€â”€ sessions table
â”‚           â”œâ”€â”€ session_id
â”‚           â”œâ”€â”€ personality_name
â”‚           â””â”€â”€ messages (JSON blob)
â”‚
â””â”€â”€ Redis (para cachÃ©)
    â””â”€â”€ session:{session_id} -> {data}
```

### Sistema v1.1 (EXTIENDE, no reemplaza)

```
TU SISTEMA v1.1:
â”œâ”€â”€ JSON files (SIGUE IGUAL)
â”‚   â””â”€â”€ session_123.json
â”‚       â”œâ”€â”€ messages: [...]
â”‚       â””â”€â”€ context: {...}
â”‚
â”œâ”€â”€ SQLite (SE AGREGAN TABLAS)
â”‚   â””â”€â”€ conversations.db
â”‚       â”œâ”€â”€ sessions (existente)
â”‚       â”œâ”€â”€ user_affinity (NUEVA)        â† Guarda afinidad
â”‚       â”œâ”€â”€ session_moods (NUEVA)        â† Guarda mood actual
â”‚       â”œâ”€â”€ user_facts (NUEVA)           â† Guarda facts
â”‚       â”œâ”€â”€ episodes (NUEVA)             â† Guarda episodios
â”‚       â””â”€â”€ message_embeddings (NUEVA)   â† Guarda vectores
â”‚
â””â”€â”€ Redis (SIGUE IGUAL)
    â””â”€â”€ session:{session_id} -> {data}
```

**TUS DATOS ACTUALES NO SE PIERDEN. Solo agregamos tablas nuevas.**

---

## ğŸ“ Memoria del LLM vs Memoria de LuminoraCore

### Memoria del LLM (Context Window)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Context Window del LLM                  â”‚
â”‚ (Ej: 8k tokens para DeepSeek)           â”‚
â”‚                                         â”‚
â”‚ Ãšltimos ~10-20 mensajes                 â”‚
â”‚ - User: "Hola"                          â”‚
â”‚ - Assistant: "Â¡Hola! Â¿CÃ³mo estÃ¡s?"     â”‚
â”‚ - User: "Bien, Â¿y tÃº?"                  â”‚
â”‚ - ...                                   â”‚
â”‚                                         â”‚
â”‚ Limitado a ventana reciente             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ventajas:
âœ… RÃ¡pido (ya en contexto)
âœ… No requiere bÃºsqueda

Desventajas:
âŒ Olvida conversaciones antiguas
âŒ No diferencia importante vs trivial
âŒ No puede "recordar hace 2 semanas..."
```

### Memoria de LuminoraCore (Ilimitada)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LuminoraCore Memory System              â”‚
â”‚ (Ilimitada, permanente)                 â”‚
â”‚                                         â”‚
â”‚ Facts (permanente):                     â”‚
â”‚ - name = "Diego"                        â”‚
â”‚ - favorite_anime = "Naruto"             â”‚
â”‚ - pet_name = "Max" (deceased)           â”‚
â”‚                                         â”‚
â”‚ Episodios (importantes):                â”‚
â”‚ - "PÃ©rdida de Max" (hace 2 semanas)     â”‚
â”‚ - "Pelea con hermana" (hace 1 mes)      â”‚
â”‚                                         â”‚
â”‚ Vector search:                          â”‚
â”‚ - BÃºsqueda semÃ¡ntica en TODO el         â”‚
â”‚   historial (meses/aÃ±os)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Ventajas:
âœ… Memoria ilimitada (aÃ±os)
âœ… Recuerda informaciÃ³n importante
âœ… BÃºsqueda semÃ¡ntica ("recuerdas cuando...")

Desventajas:
âš ï¸ Requiere retrieval (pero es rÃ¡pido ~50ms)
```

### CÃ³mo se Combinan

```python
# Al generar respuesta
async def generate_response(session_id, message):
    # 1. Obtener contexto del LLM (Ãºltimos mensajes)
    recent_messages = await db.get_messages(session_id, limit=10)
    # Estos van SIEMPRE al LLM
    
    # 2. Obtener memoria relevante de LuminoraCore
    relevant_facts = await memory.get_facts(session_id)
    relevant_episodes = await memory.search_episodes(
        query=message,
        top_k=3
    )
    
    # 3. Construir prompt combinado
    prompt = f"""
    Personality: {compiled_personality}
    
    Facts about user:
    - Name: {relevant_facts['name']}
    - Favorite anime: {relevant_facts['favorite_anime']}
    - Pet: {relevant_facts['pet_name']} (deceased)
    
    Important memories:
    - 2 weeks ago: User shared that their dog Max passed away. They were very sad.
    
    Recent conversation:
    {recent_messages}
    
    User says: {message}
    """
    
    # 4. LLM tiene TODO el contexto
    response = await llm.generate(prompt)
```

**LuminoraCore ENRIQUECE el context window del LLM con informaciÃ³n relevante del pasado.**

---

## âš¡ Performance: Optimizaciones

### 1. CachÃ© de Personalidades

```python
# NO cargar JSON cada vez
personality_cache = {}

def load_personality(name):
    if name not in personality_cache:
        personality_cache[name] = json.load(f"{name}.json")
    return personality_cache[name]  # Instant
```

### 2. Batch Processing

```python
# En lugar de:
for message in messages:
    await create_embedding(message)  # 100ms * 10 = 1000ms

# Hacer:
embeddings = await create_embeddings_batch(messages)  # 200ms total
```

### 3. Procesamiento Selectivo

```python
# NO procesar TODO cada mensaje
if message_count % 5 == 0:
    # Solo cada 5 mensajes
    await detect_episode(recent_messages)

# Fact extraction: solo si parece haber facts
if looks_like_fact(message):  # Regex simple
    await extract_facts(message)
```

### 4. Lazy Loading

```python
# NO cargar todos los facts
# Solo cargar los relevantes
relevant_facts = await db.get_facts(
    session_id,
    categories=["personal_info", "preferences"],  # Solo lo necesario
    limit=10
)
```

---

## ğŸ—‚ï¸ Estrategia de BBDD HÃ­brida

### OpciÃ³n A: Todo en SQLite (Simple)

```python
# Tu setup actual puede seguir igual
storage_config = {
    "backend": "sqlite",
    "database": "luminora.db"
}

# v1.1 agrega tablas a la misma DB
# luminora.db:
# - sessions (existente)
# - messages (existente)
# - user_affinity (nueva)
# - user_facts (nueva)
# - episodes (nueva)
# - message_embeddings (nueva, si usas pgvector alternativo)
```

**Ventajas:**
- âœ… Simple, un solo archivo
- âœ… No requiere infraestructura adicional
- âœ… MigraciÃ³n fÃ¡cil

**Desventajas:**
- âš ï¸ Vector search menos eficiente (sin pgvector extension)
- âš ï¸ Escalabilidad limitada

---

### OpciÃ³n B: HÃ­brido (Recomendado)

```python
storage_config = {
    # Conversaciones y estados (rÃ¡pido, local)
    "sessions_backend": "sqlite",          # sessions, messages
    
    # Memoria a largo plazo (persistente, cloud)
    "memory_backend": "postgresql",        # facts, episodes
    
    # CachÃ© (muy rÃ¡pido, temporal)
    "cache_backend": "redis",              # session state, compilaciones
    
    # Vector search (semÃ¡ntica)
    "vector_backend": "pgvector"           # embeddings (OPCIONAL)
}
```

**Ventajas:**
- âœ… RÃ¡pido (Redis cachÃ©)
- âœ… Persistente (PostgreSQL)
- âœ… BÃºsqueda eficiente (pgvector)
- âœ… Escalable

---

### OpciÃ³n C: Progresivo (Empezar Simple)

**Fase 1: Solo SQLite (Mes 1-2)**
```python
storage_config = {"backend": "sqlite"}
# Todo en SQLite
# Sin vector search (semantic search deshabilitado)
```

**Fase 2: SQLite + Vector Search Local (Mes 3-4)**
```python
storage_config = {
    "backend": "sqlite",
    "vector_search": "local"  # Sentence transformers (no requiere API)
}
# Vector search con embeddings locales (gratis, mÃ¡s lento)
```

**Fase 3: Production (Mes 5+)**
```python
storage_config = {
    "sessions_backend": "sqlite",
    "memory_backend": "postgresql",
    "cache_backend": "redis",
    "vector_backend": "pgvector"
}
# Full stack production
```

---

## ğŸ” RecuperaciÃ³n de Recuerdos: CÃ³mo Funciona

### Sistema Actual v1.0

```python
# v1.0 - Solo context window del LLM
recent_messages = db.get_messages(session_id, limit=10)
# [Mensaje 1, Mensaje 2, ..., Mensaje 10]

# LLM solo ve estos 10 mensajes
# Si el usuario pregunta por algo hace 2 semanas â†’ No recuerda
```

### Sistema v1.1 - Multi-Source Retrieval

```python
async def get_relevant_context(session_id, user_message):
    """
    Recupera contexto relevante de MÃšLTIPLES fuentes
    """
    # En paralelo (simultÃ¡neo)
    results = await asyncio.gather(
        # 1. Mensajes recientes (siempre, rÃ¡pido)
        db.get_recent_messages(session_id, limit=10),
        
        # 2. Facts del usuario (si relevantes)
        db.get_facts(session_id, categories=detect_categories(user_message)),
        
        # 3. Episodios relevantes (si pregunta por el pasado)
        search_episodes(session_id, query=user_message) if "recuerd" in user_message else None,
        
        # 4. BÃºsqueda semÃ¡ntica (si necesario)
        vector_search(user_message, session_id) if needs_semantic_search(user_message) else None
    )
    
    # Combinar todas las fuentes
    context = {
        "recent_messages": results[0],      # Ãšltimos 10 mensajes
        "user_facts": results[1],           # Facts relevantes
        "relevant_episodes": results[2],    # Episodios del pasado
        "similar_conversations": results[3] # Conversaciones similares
    }
    
    return context
```

### Ejemplo PrÃ¡ctico

```python
# Usuario pregunta: "Recuerdas cuando te contÃ© de Max?"

# 1. Sistema detecta: query sobre el pasado
if "recuerd" in message or "cuand" in message:
    use_semantic_search = True

# 2. RecuperaciÃ³n multi-source (paralelo, ~100ms)
context = await asyncio.gather(
    db.get_recent_messages(session_id, limit=5),        # ~20ms
    vector_search("Max perro", session_id, top_k=3),    # ~50ms (pgvector)
    db.get_episodes(session_id, tags=["pet", "Max"])    # ~30ms
)

# Resultados:
# recent_messages: Ãºltimos 5 mensajes (contexto inmediato)
# vector_search: [
#   "Mi perro Max muriÃ³ ayer" (hace 2 semanas, score: 0.92),
#   "Max era mi mejor amigo" (hace 2 semanas, score: 0.88)
# ]
# episodes: [
#   Episode(title="PÃ©rdida de Max", importance=9.5, hace 14 dÃ­as)
# ]

# 3. Construir prompt enriquecido
prompt = f"""
Personality: {compiled}

Recent conversation:
{recent_messages}

IMPORTANT MEMORY (2 weeks ago):
User shared that their dog Max passed away. They were heartbroken.
This was a very emotional moment (importance: 9.5/10).

User asks: "Recuerdas cuando te contÃ© de Max?"
"""

# 4. LLM responde con TODA la informaciÃ³n
# "Claro que sÃ­, recuerdo cuando me contaste de Max hace 2 semanas.
#  SÃ© que era muy importante para ti. Â¿CÃ³mo te sientes ahora?"
```

---

## ğŸ—ï¸ Arquitectura Completa con Capas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USUARIO                                â”‚
â”‚                  "Recuerdas cuando..."                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LUMINORACORE SDK                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CAPA DE ORQUESTACIÃ“N (Main Thread)                â”‚
â”‚  - Coordina todo el flujo                                      â”‚
â”‚  - Maneja foreground (respuesta rÃ¡pida)                        â”‚
â”‚  - Lanza background tasks                                      â”‚
â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚        â”‚        â”‚        â”‚
   â”‚        â”‚        â”‚        â”‚
   â–¼        â–¼        â–¼        â–¼
â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Cacheâ”‚ â”‚BBDD â”‚ â”‚BBDD â”‚ â”‚BBDD      â”‚
â”‚Layerâ”‚ â”‚Rel. â”‚ â”‚Vec. â”‚ â”‚LLM Mem.  â”‚
â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚        â”‚        â”‚         â”‚
  â”‚        â”‚        â”‚         â”‚
  â–¼        â–¼        â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STORAGE BACKENDS                     â”‚
â”‚                                      â”‚
â”‚ Redis         SQLite/PostgreSQL      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚ â”‚Sessions  â”‚  â”‚Messages       â”‚      â”‚
â”‚ â”‚Moods     â”‚  â”‚Affinity       â”‚      â”‚
â”‚ â”‚Cache     â”‚  â”‚Facts          â”‚      â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚Episodes       â”‚      â”‚
â”‚               â”‚Embeddings     â”‚      â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Flujo Detallado: Primera ConversaciÃ³n vs ConversaciÃ³n Continua

### Primera ConversaciÃ³n (Cold Start)

```python
# Usuario crea sesiÃ³n por primera vez
session_id = await client.create_session(
    personality_name="alicia",
    provider_config={...}
)

# Sistema inicializa:
# 1. Cargar JSON de personalidad (del disco)
personality_json = load_json("alicia.json")  # ~10ms

# 2. Crear entrada en BBDD
await db.insert({
    "table": "user_affinity",
    "data": {
        "user_id": user_id,
        "personality_name": "alicia",
        "affinity_points": 0,      # Empieza en 0
        "current_level": "stranger"
    }
})

await db.insert({
    "table": "session_moods",
    "data": {
        "session_id": session_id,
        "current_mood": "neutral",  # Empieza en neutral
        "mood_intensity": 1.0
    }
})

# 3. Cachear personalidad en Redis
await redis.set(f"personality:alicia", personality_json, ex=3600)

# Listo para chatear
```

### ConversaciÃ³n Continua (Warm)

```python
# Usuario envÃ­a mensaje #1
response = await client.send_message(session_id, "Hola")

# Foreground (usuario espera):
# 1. Cargar desde cachÃ© (~1ms)
personality = await redis.get("personality:alicia")  # CachÃ© hit
affinity = await redis.get(f"affinity:{session_id}")  # CachÃ© hit
mood = await redis.get(f"mood:{session_id}")         # CachÃ© hit

# 2. Compilar (~5ms)
compiled = apply_modifiers(personality, affinity=0, mood="neutral")

# 3. LLM (~1500ms)
response = await llm.generate(compiled + "Hola")

# 4. Retornar
return response  # Usuario ve respuesta aquÃ­ (1.5s)

# Background (async):
# 5. Actualizar estado
affinity_new = 1  # +1 por primer mensaje
await db.update("user_affinity", affinity=1)
await redis.set(f"affinity:{session_id}", 1, ex=3600)  # Actualizar cachÃ©

# Usuario envÃ­a mensaje #2
response = await client.send_message(session_id, "Eres linda")

# Foreground:
# 1. Cargar desde cachÃ© (~1ms) - MÃS RÃPIDO
affinity = 1  # Ya en cachÃ©
mood = "neutral"

# 2. Detectar nuevo mood (paralelo con LLM)
asyncio.create_task(detect_mood("Eres linda"))  # Background

# 3. Compilar con mood actual (~5ms)
compiled = apply_modifiers(personality, affinity=1, mood="neutral")

# 4. LLM (~1500ms)
response = await llm.generate(compiled + "Eres linda")

# 5. Retornar
return response

# Background:
# 6. Mood detectado
new_mood = "shy"
await db.update("session_moods", mood="shy", intensity=0.3)
await redis.set(f"mood:{session_id}", "shy", ex=3600)

# 7. Actualizar affinity
affinity = 1 + 2 = 3  # +2 por cumplido
await db.update("user_affinity", affinity=3)
```

---

## ğŸ’¡ SoluciÃ³n a tus Preocupaciones

### PreocupaciÃ³n 1: "Recompilar cada vez es lento"

**SoluciÃ³n:** CompilaciÃ³n es TRIVIAL (~5ms), el LLM es lo lento (~1500ms)

```
Total tiempo de respuesta:
- Cargar contexto: 50ms (con cachÃ©: 1ms)
- Compilar: 5ms
- LLM: 1500ms â† 99% del tiempo
- Total: 1555ms

Si eliminÃ¡ramos la compilaciÃ³n:
- Total: 1550ms (diferencia: 5ms = 0.3%)

ConclusiÃ³n: La compilaciÃ³n es IRRELEVANTE vs el LLM
```

### PreocupaciÃ³n 2: "Â¿CuÃ¡ndo se actualiza el JSON?"

**Respuesta:** NUNCA. El JSON NO se actualiza.

```
alicia.json (archivo en disco)
  â†“ Carga UNA VEZ
Memoria RAM (objeto Python)
  â†“ Aplica modificadores TEMPORALMENTE
Personalidad compilada (en RAM, por request)
  â†“ Se usa para generar respuesta
  â†“ Se DESCARTA despuÃ©s
```

### PreocupaciÃ³n 3: "Â¿DÃ³nde persiste el estado?"

**Respuesta:** En BBDD (tu elecciÃ³n: SQLite, PostgreSQL, etc.)**

```sql
-- Estos datos PERSISTEN entre sesiones
SELECT * FROM user_affinity WHERE user_id='diego';
-- affinity_points: 45
-- current_level: "friend"

SELECT * FROM session_moods WHERE session_id='session_123';
-- current_mood: "shy"
-- mood_intensity: 0.7

SELECT * FROM user_facts WHERE user_id='diego';
-- name: "Diego"
-- favorite_anime: "Naruto"
-- pet_name: "Max" (deceased)
```

### PreocupaciÃ³n 4: "Â¿Proceso paralelo con IA?"

**Respuesta:** SÃ, ya estÃ¡ diseÃ±ado asÃ­ (background tasks)**

```python
# Usuario NO espera estas tareas
asyncio.create_task(extract_facts(message))      # Background
asyncio.create_task(detect_episode(messages))    # Background
asyncio.create_task(create_embeddings(message))  # Background
asyncio.create_task(update_analytics(session))   # Background
```

### PreocupaciÃ³n 5: "Â¿QuÃ© pasa con JSON/SQLite actuales?"

**Respuesta:** SIGUEN FUNCIONANDO. Solo agregamos tablas.**

```python
# TU CÃ“DIGO ACTUAL (sigue igual)
messages = await db.get_messages(session_id)  # SQLite
conversation = load_json(f"session_{session_id}.json")  # JSON file

# v1.1 AGREGA (no reemplaza)
affinity = await db.get_affinity(session_id)      # Nueva tabla en SQLite
facts = await db.get_facts(session_id)            # Nueva tabla en SQLite
episodes = await db.get_episodes(session_id)      # Nueva tabla en SQLite
```

**No pierdes nada de lo que tienes.**

---

## ğŸ“‹ MigraciÃ³n desde v1.0

```bash
# 1. Backup de BBDD actual
cp luminora.db luminora.db.backup

# 2. Ejecutar migraciÃ³n
luminora-cli migrate --from 1.0 --to 1.1

# Crea tablas nuevas:
# - user_affinity
# - session_moods  
# - user_facts
# - episodes
# - message_embeddings (si vector search habilitado)

# 3. Datos existentes NO se tocan
# - sessions (intacto)
# - messages (intacto)
# - Tu estructura actual (intacta)
```

---

## âš¡ Performance Real: Benchmarks

### Sin OptimizaciÃ³n (Naive)

```
Mensaje â†’ Respuesta
â”œâ”€ Load personality JSON: 10ms
â”œâ”€ Load affinity from DB: 15ms
â”œâ”€ Load mood from DB: 15ms
â”œâ”€ Compile personality: 5ms
â”œâ”€ LLM generate: 1500ms
â”œâ”€ Background tasks: 400ms (async, no bloquea)
â””â”€ TOTAL visible: 1545ms
```

### Con OptimizaciÃ³n (CachÃ©)

```
Mensaje â†’ Respuesta
â”œâ”€ Load personality (cachÃ©): 0.1ms
â”œâ”€ Load affinity (cachÃ©): 0.5ms
â”œâ”€ Load mood (cachÃ©): 0.5ms
â”œâ”€ Compile personality: 5ms
â”œâ”€ LLM generate: 1500ms
â”œâ”€ Background tasks: 400ms (async)
â””â”€ TOTAL visible: 1506ms
```

**Diferencia: 39ms (2.5% overhead)**

### Con Streaming

```
Mensaje â†’ Primera palabra visible
â”œâ”€ Load context (cachÃ©): 1ms
â”œâ”€ Compile: 5ms
â”œâ”€ LLM streaming: 200ms â† Primera palabra
â””â”€ TOTAL: 206ms âœ…

Usuario ve primera palabra en 200ms
Resto llega progresivamente (streaming)
```

---

## ğŸ—„ï¸ Estructura de BBDD Completa

### SQLite (OpciÃ³n Simple)

```sql
-- TU BBDD ACTUAL (v1.0, sin cambios)
CREATE TABLE sessions (
    session_id TEXT PRIMARY KEY,
    user_id TEXT,
    personality_name TEXT,
    created_at TIMESTAMP,
    last_activity TIMESTAMP
);

CREATE TABLE messages (
    id TEXT PRIMARY KEY,
    session_id TEXT,
    speaker TEXT,  -- "user" | "assistant"
    content TEXT,
    timestamp TIMESTAMP
);

-- NUEVAS TABLAS v1.1 (agregadas, no reemplazadas)
CREATE TABLE user_affinity (
    user_id TEXT,
    personality_name TEXT,
    affinity_points INTEGER DEFAULT 0,
    current_level TEXT DEFAULT 'stranger',
    last_updated TIMESTAMP,
    PRIMARY KEY (user_id, personality_name)
);

CREATE TABLE session_moods (
    session_id TEXT PRIMARY KEY,
    current_mood TEXT DEFAULT 'neutral',
    mood_intensity REAL DEFAULT 1.0,
    mood_started_at TIMESTAMP
);

CREATE TABLE user_facts (
    id TEXT PRIMARY KEY,
    user_id TEXT,
    category TEXT,
    key TEXT,
    value TEXT,  -- JSON string
    confidence REAL,
    first_mentioned TIMESTAMP,
    UNIQUE(user_id, category, key)
);

CREATE TABLE episodes (
    id TEXT PRIMARY KEY,
    user_id TEXT,
    session_id TEXT,
    type TEXT,
    title TEXT,
    summary TEXT,
    importance REAL,
    sentiment TEXT,
    tags TEXT,  -- JSON array
    timestamp TIMESTAMP
);

-- OPCIONAL: Si usas vector search con extensiÃ³n
CREATE TABLE message_embeddings (
    message_id TEXT PRIMARY KEY,
    user_id TEXT,
    embedding BLOB,  -- numpy array serializado
    metadata TEXT    -- JSON
);
```

---

## ğŸ”‘ Respuesta Final a Todas tus Dudas

### 1. Â¿JSON se actualiza?
**NO. JSON es inmutable. Estados en BBDD.**

### 2. Â¿Recompila cada mensaje?
**SÃ, pero es rÃ¡pido (~5ms). El LLM es lo lento.**

### 3. Â¿Solo persiste durante chat?
**NO. Persiste PERMANENTEMENTE en BBDD.**

### 4. Â¿CÃ³mo clasifica quÃ© va al JSON?
**Nada va al JSON. Estados van a BBDD.**

### 5. Â¿Proceso mÃ¡s lento?
**NO. Background tasks no bloquean (async).**

### 6. Â¿Proceso paralelo con IA?
**SÃ. Fact extraction, mood detection, etc. son async.**

### 7. Â¿QuÃ© pasa con JSON/SQLite actuales?
**Siguen funcionando. Solo agregamos tablas.**

### 8. Â¿BBDD vectorial reemplaza actuales?
**NO. Es ADICIONAL (solo para semantic search).**

### 9. Â¿CÃ³mo recupera recuerdos?
**Multi-source: mensajes recientes + facts + episodios + vector search.**

### 10. Â¿Memoria del LLM?
**LuminoraCore ENRIQUECE el context window con info del pasado.**

---

## ğŸ“Š Tabla Resumen de Persistencia

| Dato | DÃ³nde se Define | DÃ³nde Persiste | Mutable | Lifetime |
|------|----------------|----------------|---------|----------|
| **Personalidad base** | `alicia.json` | Archivo JSON | âŒ NO | Permanente |
| **Niveles posibles** | `alicia.json` | Archivo JSON | âŒ NO | Permanente |
| **Moods posibles** | `alicia.json` | Archivo JSON | âŒ NO | Permanente |
| **Affinity actual** | - | BBDD (SQLite/PostgreSQL) | âœ… SÃ | Permanente |
| **Mood actual** | - | BBDD + CachÃ© (Redis) | âœ… SÃ | SesiÃ³n o permanente |
| **Mensajes** | - | BBDD (SQLite/PostgreSQL) | âœ… SÃ | Permanente |
| **Facts** | - | BBDD (SQLite/PostgreSQL) | âœ… SÃ | Permanente |
| **Episodios** | - | BBDD (SQLite/PostgreSQL) | âœ… SÃ | Permanente |
| **Embeddings** | - | BBDD Vector (pgvector/Pinecone) | âœ… SÃ | Permanente |
| **Personalidad compilada** | - | RAM (temporal, por request) | - | 1 request |

---

<div align="center">

**Made with â¤ï¸ by Ereace - Ruly Altamirano**

</div>

