# ğŸ§ª LuminoraCore Test Suite

## ğŸ“‹ Suite Completa de Pruebas

Esta es la **suite de validaciÃ³n exhaustiva** antes del lanzamiento v1.0.

### ğŸ¯ FilosofÃ­a

> "No lanzaremos nada que sea una mierda. Se probarÃ¡n todas las caracterÃ­sticas exhaustivamente."

---

## ğŸ“Š Test Suites

| Suite | Archivo | Tests | Estado | Prioridad |
|-------|---------|-------|--------|-----------|
| 1. Motor Base | `test_1_motor_base.py` | 30 | â³ | ğŸ”´ CRÃTICO |
| 2. CLI | `test_2_cli.py` | 25 | â³ | ğŸŸ¡ ALTO |
| 3. Providers | `test_3_providers.py` | 49 | â³ | ğŸ”´ CRÃTICO |
| 4. Storage | `test_4_storage.py` | 36 | â³ | ğŸ”´ CRÃTICO |
| 5. Sessions | `test_5_sessions.py` | 25 | â³ | ğŸŸ¡ ALTO |
| 6. Integration | `test_6_integration.py` | 8 | â³ | ğŸ”´ CRÃTICO |
| **TOTAL** | | **173** | | |

---

## ğŸš€ InstalaciÃ³n

### Requisitos

```bash
pip install pytest pytest-asyncio pytest-cov pytest-benchmark
```

### Setup

```bash
# 1. Instalar LuminoraCore en modo desarrollo
cd luminoracore
pip install -e ".[all]"

# 2. Configurar API keys (para test_3_providers.py)
export OPENAI_API_KEY="sk-..."
export ANTHROPIC_API_KEY="sk-ant-..."
export DEEPSEEK_API_KEY="sk-..."
# ... etc

# 3. Setup de databases (para test_4_storage.py)
docker-compose -f tests/docker-compose.yml up -d
```

---

## ğŸ§ª EjecuciÃ³n

### Ejecutar TODO

```bash
# Desde el directorio raÃ­z del proyecto
pytest tests/ -v

# Con coverage
pytest tests/ -v --cov=luminoracore --cov-report=html

# En paralelo (mÃ¡s rÃ¡pido)
pytest tests/ -n auto
```

### Ejecutar Suite EspecÃ­fica

```bash
# Solo Motor Base
pytest tests/test_1_motor_base.py -v

# Solo Providers
pytest tests/test_3_providers.py -v

# Solo con marca especÃ­fica
pytest tests/ -m "critical" -v
```

### Ejecutar Test EspecÃ­fico

```bash
# Un test particular
pytest tests/test_1_motor_base.py::TestPersonalityLoading::test_load_from_valid_file -v
```

---

## ğŸ“ˆ Coverage

### Generar Reporte

```bash
pytest tests/ --cov=luminoracore --cov-report=html

# Abrir reporte
open htmlcov/index.html  # Mac
start htmlcov/index.html  # Windows
xdg-open htmlcov/index.html  # Linux
```

### Objetivo

- **MÃ­nimo aceptable**: 70% coverage
- **Ideal**: 85%+ coverage
- **Core critical paths**: 100% coverage

---

## ğŸ³ Docker para Testing

### Setup de Databases

```bash
cd tests
docker-compose up -d
```

Esto levanta:
- Redis (puerto 6379)
- PostgreSQL (puerto 5432)
- MongoDB (puerto 27017)

### Cleanup

```bash
docker-compose down -v
```

---

## ğŸ” Estructura de Tests

### Convenciones

```python
# tests/test_X_nombre.py

class TestFeatureGroup:
    """Tests de un grupo de funcionalidades."""
    
    @pytest.fixture
    def setup_data(self):
        """Fixture para datos de prueba."""
        return {"key": "value"}
    
    def test_specific_behavior(self, setup_data):
        """âœ… DescripciÃ³n clara del test."""
        # Given (setup)
        # When (acciÃ³n)
        # Then (assert)
        assert True

# Marcas
@pytest.mark.critical  # Test crÃ­tico para lanzamiento
@pytest.mark.slow  # Test lento (> 1s)
@pytest.mark.integration  # Test de integraciÃ³n
@pytest.mark.requires_api  # Requiere API key
```

### Nombres de Tests

- âœ… `test_load_from_valid_file` - Descriptivo
- âŒ `test_1` - No descriptivo

---

## âš™ï¸ ConfiguraciÃ³n

### pytest.ini

```ini
[pytest]
minversion = 6.0
addopts = -ra -q --strict-markers
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
markers =
    critical: Critical tests for v1.0 release
    slow: Tests que tardan > 1s
    integration: Integration tests
    requires_api: Requires API key
    requires_db: Requires database
```

### conftest.py

Fixtures compartidas para todos los tests.

---

## ğŸš¨ Tests CrÃ­ticos

### MUST PASS para lanzar v1.0

```bash
pytest tests/ -m "critical" -v
```

Todos estos tests DEBEN pasar antes de lanzar:

1. **Motor Base**: Carga, validaciÃ³n, compilaciÃ³n
2. **Providers**: Al menos 5/7 providers funcionando
3. **Storage**: Memory, JSON, SQLite funcionando
4. **Sessions**: Crear, enviar mensajes, historial
5. **Integration**: Chatbot bÃ¡sico funciona end-to-end

---

## ğŸ› Troubleshooting

### Tests fallan con "module not found"

```bash
# AsegÃºrate de instalar en modo desarrollo
pip install -e "luminoracore/[all]"
```

### Tests de providers fallan con "API key not configured"

```bash
# Configura la API key
export PROVIDER_API_KEY="your-key"

# O skip esos tests
pytest tests/ -m "not requires_api"
```

### Tests de storage fallan con "connection refused"

```bash
# Levanta las databases
cd tests
docker-compose up -d

# Verifica que estÃ©n corriendo
docker-compose ps
```

### Tests lentos

```bash
# Skip tests lentos
pytest tests/ -m "not slow"

# O ejecuta en paralelo
pytest tests/ -n auto
```

---

## ğŸ“Š CI/CD

### GitHub Actions

Los tests se ejecutan automÃ¡ticamente en cada push:

```yaml
# .github/workflows/test.yml
name: Test Suite
on: [push, pull_request]
jobs:
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python: ['3.9', '3.10', '3.11']
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
      - run: pip install -e ".[all]"
      - run: pytest tests/ -v --cov
```

### Pre-commit Hook

```bash
# Instalar pre-commit
pip install pre-commit

# Activar
pre-commit install

# Los tests se ejecutarÃ¡n antes de cada commit
```

---

## ğŸ“ Contribuir

### Agregar Nuevo Test

1. Identifica la suite correcta (`test_X_nombre.py`)
2. Agrega el test con nombre descriptivo
3. Marca apropiadamente (`@pytest.mark.critical`)
4. Ejecuta la suite: `pytest tests/test_X_nombre.py -v`
5. Verifica coverage: `pytest tests/test_X_nombre.py --cov`

### Reportar Test que Falla

1. Anota el nombre completo del test
2. Copia el error completo
3. Documenta en GitHub Issues con label "test-failure"
4. Indica prioridad (critical/high/medium/low)

---

## ğŸ¯ Objetivos de Calidad

### Antes del Lanzamiento

- âœ… **173/173 tests passing** (o justificar por quÃ© no)
- âœ… **0 tests crÃ­ticos fallando**
- âœ… **Coverage > 70%**
- âœ… **0 flaky tests** (tests que fallan intermitentemente)
- âœ… **Suite completa < 5 minutos** (sin API calls reales)

### MÃ©tricas de Ã‰xito

```bash
# Ejecutar y generar reporte
pytest tests/ -v --cov --cov-report=term-missing

# Resultado esperado:
# ============= 173 passed in 180.00s =============
# Coverage: 75%
```

---

## ğŸ“ Contacto

**Test Suite Owner**: Responsable de mantener los tests

**Issues**: GitHub Issues con label "tests"

**Docs**: Ver `MASTER_TEST_SUITE.md` para plan completo

---

**Ãšltima actualizaciÃ³n**: 2025-01-04  
**Estado**: ğŸŸ¡ En construcciÃ³n  
**Cobertura actual**: 0% (tests pendientes)

